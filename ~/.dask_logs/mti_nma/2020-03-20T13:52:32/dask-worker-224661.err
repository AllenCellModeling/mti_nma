distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.5.184:46355'
/home/juliec/miniconda3/envs/mti_nma_viz/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
distributed.worker - INFO -       Start worker at:   tcp://172.20.5.184:36151
distributed.worker - INFO -          Listening to:   tcp://172.20.5.184:36151
distributed.worker - INFO -          dashboard at:         172.20.5.184:42995
distributed.worker - INFO - Waiting to connect to:   tcp://172.20.5.206:33663
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          2
distributed.worker - INFO -                Memory:                   24.00 GB
distributed.worker - INFO -       Local Directory: /home/juliec/.dask_logs/mti_nma/2020-03-20T13:52:32/worker-dil8bkmm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.20.5.206:33663
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.utils_perf - INFO - full garbage collection released 21.36 MB from 953 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 36.32 MB from 1653 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 26.81 MB from 1977 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 12.71 MB from 2178 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 17.51 MB from 2166 reference cycles (threshold: 10.00 MB)
distributed.core - INFO - Event loop was unresponsive in Worker for 12.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils_perf - INFO - full garbage collection released 22.81 MB from 1182 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 42.20 MB from 1982 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 33.62 MB from 1937 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 40.94 MB from 2495 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - INFO - full garbage collection released 28.79 MB from 1970 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - INFO - full garbage collection released 28.91 MB from 2239 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - INFO - full garbage collection released 16.60 MB from 2080 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Stopping worker at tcp://172.20.5.184:36151
slurmstepd-n184: error: *** JOB 224661 ON n184 CANCELLED AT 2020-03-20T13:55:06 ***
